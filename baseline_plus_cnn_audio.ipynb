{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k__XMdb11kn1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cUSTHcInaco"
   },
   "source": [
    "# An important aspect of models processing raw audio data is the receptive field of their first layer’s filters. Our model’s first filter is length 80 so when processing audio sampled at 8kHz the receptive field is around 10ms (and at 4kHz, around 20 ms). This size is similar to speech processing applications that often use receptive fields ranging from 20ms to 40ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gf3pLo7ZmReW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_for_audio(nn.Module):\n",
    "    def __init__(self, n_input=1, num_classes=35, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.n_input=n_input\n",
    "        self.num_classes=num_classes\n",
    "        self.stride=n_output\n",
    "        self.n_channel=n_channel\n",
    "\n",
    "    def block(self,in_features,out_features,kernel):\n",
    "        block=nn.Sequential(nn.Conv1d(in_features, out_features, kernel, 4),\n",
    "                            nn.BatchNorm1d(out_features),\n",
    "                            nn.Relu,\n",
    "                            nn.MaxPool1d(4))\n",
    "        return block\n",
    "\n",
    "        self.final_layer = nn.Linear(2 * n_channel, num_classes)\n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.block(self.n_input,self.n_channel,80,self.stride)(x)\n",
    "        x=self.block(self.n_channel,self.n_channel,3)(x)\n",
    "        x=self.block(self.n_channel,2*self.n_channel,3)(x)\n",
    "        x=self.block(2*self.n_channel,2*self.n_channel,3)(x)\n",
    "        x=self.final_layer(x)\n",
    "        output=F.log_softmax(x, dim=2)\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwLFlYx61nJo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class LSTM_for_baseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes,dropout):\n",
    "        super(LSTM_for_baseline, self).__init__()\n",
    "\n",
    "        self.num_classes=num_classes\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout=dropout\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm_layer = nn.LSTM(input_size self.hidden_size, self.num_layers, batch_first=True, dropout=self.dropout)\n",
    "        self.linear1 = nn.Linear(self.hidden_size, self.hidden_size//2)\n",
    "        self.sctivation = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(self.hidden_size//2, self.hidden_size//2)\n",
    "        self.linear3 = nn.Linear(self.hidden_size//2, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float()).to(device)\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float()).to(device)\n",
    "        x, _ = self.lstm_layer(x, (h0,c0)) \n",
    "\n",
    "        x=self.linear1(x[:, -1, :])\n",
    "        x = self.activation(x)\n",
    "        x=self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear3(x) \n",
    "        output=F.log_softmax(x, dim=2)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw_JPPsr1nMi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIxJwtcC1nUF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNOFMEqb1nWS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5q9lBMZ1nYl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg10fnrg1nbN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6Xqpw9F1ndg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p79a_JVD1ngA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I_u1mQ71nia"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYRR_GCn1nkh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "baseline_plus_cnn_audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
